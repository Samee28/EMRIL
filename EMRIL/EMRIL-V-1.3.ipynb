{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac834adc-63f9-4cf6-a140-cb30571f96d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "Successfully installed numpy-2.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e611383f-6279-40f8-9107-011a050270f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting river\n",
      "  Downloading river-0.22.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from river) (2.2.5)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.2.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from river) (2.2.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.14.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from river) (1.15.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0.0,>=2.2.3->river) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0.0,>=2.2.3->river) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0.0,>=2.2.3->river) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.3->river) (1.17.0)\n",
      "Downloading river-0.22.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: river\n",
      "Successfully installed river-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install river\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a822d24-e686-4171-b020-42c00c0bdb60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18159\n",
      "8\n",
      "1s: 0.6862162013326725\n",
      "0s: 0.0\n",
      "1.6509418999776244\n",
      "3.4743025999050587\n",
      "5.082432699971832\n",
      "5.924085199949332\n",
      "6.8449452999047935\n",
      "7.526902299956419\n",
      "8.340357499895617\n",
      "9.165918199927546\n",
      "9.934717700001784\n",
      "10.589988399995491\n",
      "11.238443899899721\n",
      "12.069579999893904\n",
      "13.030603799968958\n",
      "14.107763799955137\n",
      "15.227222999907099\n",
      "16.032174699939787\n",
      "16.738560499972664\n",
      "17.38073049997911\n",
      "18.139499899931252\n",
      "18.871488599921577\n",
      "19.7406627999153\n",
      "20.56391749996692\n",
      "21.38036359997932\n",
      "22.234897299902514\n",
      "23.130818799952976\n",
      "23.898961999919266\n",
      "24.58865779999178\n",
      "25.298990199924447\n",
      "28.211766799911857\n",
      "30.10611319995951\n",
      "30.918482299894094\n",
      "31.747981299995445\n",
      "32.66764159989543\n",
      "33.44636169995647\n",
      "34.11117859999649\n",
      "34.784039499936625\n",
      "35.43057419999968\n",
      "36.064498899970204\n",
      "36.74866179993842\n",
      "37.5685903999256\n",
      "38.31238989997655\n",
      "39.0270347999176\n",
      "39.700134399929084\n",
      "40.39229369990062\n",
      "41.0237062999513\n",
      "41.646084699896164\n",
      "42.31691850000061\n",
      "42.93497639999259\n",
      "43.628309799940325\n",
      "45.05649839993566\n",
      "46.0322902998887\n",
      "46.954780299915\n",
      "47.989613199955784\n",
      "49.0460317999823\n",
      "49.85057869995944\n",
      "50.47527589998208\n",
      "51.136159499990754\n",
      "51.842591999913566\n",
      "52.64218049996998\n",
      "53.325224999920465\n",
      "53.91567269992083\n",
      "54.68839259992819\n",
      "55.32796079991385\n",
      "55.98153939994518\n",
      "56.62009219999891\n",
      "57.23161599994637\n",
      "57.86599649989512\n",
      "58.48375289991964\n",
      "59.08823529991787\n",
      "59.7417090999661\n",
      "60.352162599912845\n",
      "60.995877699926496\n",
      "61.601640199893154\n",
      "62.20959819993004\n",
      "62.82520159997512\n",
      "63.407100899959914\n",
      "64.03021079988685\n",
      "64.6147569998866\n",
      "65.19697699998505\n",
      "65.87037059990689\n",
      "66.6478591999039\n",
      "67.41996179998387\n",
      "68.03394469991326\n",
      "68.69315449998248\n",
      "69.28227699990384\n",
      "69.86673739994876\n",
      "70.48403099994175\n",
      "71.04875729989726\n",
      "71.69637629995123\n",
      "72.24983769992832\n",
      "72.8990146999713\n",
      "0.5956973000429571\n",
      "2.0641415000427514\n",
      "2.687365800025873\n",
      "3.3944445999804884\n",
      "3.9814135000342503\n",
      "4.66749040002469\n",
      "5.3301663000602275\n",
      "6.044732099981047\n",
      "6.728428700007498\n",
      "7.393563500023447\n",
      "8.005280000041239\n",
      "8.670754800084978\n",
      "9.382781899999827\n",
      "10.09563460003119\n",
      "11.42006020003464\n",
      "12.149076100089587\n",
      "13.296422600047663\n",
      "13.998356600059196\n",
      "14.75429409998469\n",
      "15.602947700070217\n",
      "16.332704600063153\n",
      "17.101196600007825\n",
      "17.85875210002996\n",
      "18.58041830000002\n",
      "19.53039590001572\n",
      "20.290363100008108\n",
      "20.964170000050217\n",
      "21.61849510006141\n",
      "22.326128600048833\n",
      "22.977882700040936\n",
      "23.64037650008686\n",
      "24.45503449998796\n",
      "25.24979480006732\n",
      "26.014866600045934\n",
      "26.77645190001931\n",
      "27.443172900006175\n",
      "28.257725100032985\n",
      "28.968741900054738\n",
      "29.707051699981093\n",
      "30.430220799986273\n",
      "31.154723800020292\n",
      "31.924606600077823\n",
      "32.75452810002025\n",
      "33.58155310002621\n",
      "34.37349210004322\n",
      "35.07218590006232\n",
      "35.75364850007463\n",
      "36.53798350004945\n",
      "39.00604150001891\n",
      "41.19877100002486\n",
      "42.46235060004983\n",
      "43.43623170000501\n",
      "44.24868110008538\n",
      "44.92853720008861\n",
      "45.592095100088045\n",
      "46.22795870003756\n",
      "46.91820000007283\n",
      "47.6276411000872\n",
      "48.7420892000664\n",
      "49.38042709999718\n",
      "50.02188470005058\n",
      "50.685927400016226\n",
      "51.371920600067824\n",
      "51.983139600022696\n",
      "52.65743720007595\n",
      "53.363678300054744\n",
      "54.082938299980015\n",
      "54.76947290007956\n",
      "55.37675679998938\n",
      "55.98203579999972\n",
      "56.942554200068116\n",
      "57.699486700003035\n",
      "58.4621146999998\n",
      "59.22436440002639\n",
      "60.004552200087346\n",
      "60.78494739998132\n",
      "61.541646099998616\n",
      "62.51519880001433\n",
      "63.24910210003145\n",
      "63.9490630000364\n",
      "64.89842740003951\n",
      "65.60530669998843\n",
      "66.30765490001068\n",
      "67.04255580005702\n",
      "67.72806100000162\n",
      "68.47180930001196\n",
      "69.21586450003088\n",
      "69.85340660007205\n",
      "70.4928571000928\n",
      "71.0996125000529\n",
      "71.98556030006148\n",
      "0.6835806999588385\n",
      "2.214610999915749\n",
      "2.9517765999771655\n",
      "4.258156999945641\n",
      "5.07460239995271\n",
      "6.108853199984878\n",
      "8.902486099977978\n",
      "11.340816299896687\n",
      "12.699124099919572\n",
      "14.024354299996048\n",
      "15.34402879991103\n",
      "16.76685109990649\n",
      "18.18018599995412\n",
      "18.90521319990512\n",
      "19.862318399944343\n",
      "20.516504399944097\n",
      "21.15790309989825\n",
      "21.845852399943396\n",
      "22.843459199997596\n",
      "23.497338099987246\n",
      "24.193286399939097\n",
      "24.85301629989408\n",
      "25.46873819991015\n",
      "26.100749199977145\n",
      "26.72276909998618\n",
      "27.409967199899256\n",
      "28.133064199937508\n",
      "28.755281599937007\n",
      "29.34805189992767\n",
      "29.982661699992605\n",
      "30.562647699960507\n",
      "31.136548799928278\n",
      "31.766925200005062\n",
      "32.50158019992523\n",
      "33.17978099989705\n",
      "33.88401179993525\n",
      "34.67367349995766\n",
      "35.329078499926254\n",
      "36.04491049994249\n",
      "36.7322867999319\n",
      "37.380751699907705\n",
      "38.08333539997693\n",
      "38.73609839996789\n",
      "39.377377399941906\n",
      "40.02972609992139\n",
      "40.648420299985446\n",
      "41.23245659994427\n",
      "41.93077859992627\n",
      "42.66081439994741\n",
      "44.08415839995723\n",
      "44.796455599949695\n",
      "45.530654300004244\n",
      "46.27547999995295\n",
      "47.05737619998399\n",
      "47.87154969992116\n",
      "48.70706839999184\n",
      "49.48587889992632\n",
      "50.22342709999066\n",
      "50.97266159998253\n",
      "51.64538379991427\n",
      "52.24879969994072\n",
      "52.90283889998682\n",
      "53.60741529997904\n",
      "54.381164499907754\n",
      "55.16612700000405\n",
      "55.97005409991834\n",
      "57.17743989999872\n",
      "58.435076499939896\n",
      "59.27858919999562\n",
      "60.59550279995892\n",
      "61.36739019991364\n",
      "62.181048099999316\n",
      "63.06295389996376\n",
      "63.87985249992926\n",
      "64.70868169993628\n",
      "65.48796469997615\n",
      "67.13386379997246\n",
      "68.32835839991458\n",
      "69.4261938999407\n",
      "70.18278289993759\n",
      "71.44649359991308\n",
      "72.68713019997813\n",
      "73.58614509995095\n",
      "74.2538285999326\n",
      "74.92313659994397\n",
      "75.60477659991011\n",
      "76.2045352999121\n",
      "76.85032849991694\n",
      "77.59190279990435\n",
      "78.19243749999441\n",
      "78.82117179990746\n",
      "0.7007779999403283\n",
      "2.063268300029449\n",
      "2.637353300000541\n",
      "3.34820160001982\n",
      "4.011721199960448\n",
      "4.667147799977101\n",
      "5.299614300020039\n",
      "5.892401400022209\n",
      "6.530392799992114\n",
      "7.232088399934582\n",
      "7.903337099938653\n",
      "8.52248739998322\n",
      "9.41908899997361\n",
      "10.14014989999123\n",
      "10.92722870002035\n",
      "11.701451899949461\n",
      "12.36973549996037\n",
      "13.0365310999332\n",
      "13.735917799989693\n",
      "14.409015499986708\n",
      "15.049612000002526\n",
      "15.713392499950714\n",
      "16.395720300031826\n",
      "17.087126899976283\n",
      "17.726162799983285\n",
      "18.375648799934424\n",
      "19.148428099928424\n",
      "20.047440399997868\n",
      "20.665856200037524\n",
      "21.335384399979375\n",
      "21.952106799930334\n",
      "22.648272900027223\n",
      "23.323639299953356\n",
      "24.000185600016266\n",
      "24.729300700011663\n",
      "25.442682900000364\n",
      "26.120685199974105\n",
      "26.769863600027747\n",
      "27.39176139992196\n",
      "28.006326899980195\n",
      "28.6875092999544\n",
      "29.37733449996449\n",
      "30.021000399952754\n",
      "30.633578400011174\n",
      "31.27435449999757\n",
      "31.92216770001687\n",
      "32.59023929992691\n",
      "33.30514750001021\n",
      "33.93321039993316\n",
      "35.193655899958685\n",
      "35.82184669992421\n",
      "36.50895899999887\n",
      "37.14088560000528\n",
      "37.8072335999459\n",
      "38.48910869995598\n",
      "39.14036219997797\n",
      "39.800668200012296\n",
      "40.397236999939196\n",
      "41.08210629993118\n",
      "41.68411319993902\n",
      "42.30697119992692\n",
      "42.951782000018284\n",
      "43.592112399986945\n",
      "44.330404500011355\n",
      "45.03211739996914\n",
      "45.676450600032695\n",
      "46.23291200003587\n",
      "46.81433790002484\n",
      "47.67313769995235\n",
      "48.34187180001754\n",
      "48.97768100001849\n",
      "49.648776500020176\n",
      "50.37350190000143\n",
      "51.10126349993516\n",
      "51.84517879993655\n",
      "52.47804519999772\n",
      "53.176967400009744\n",
      "53.93195759993978\n",
      "54.596977600012906\n",
      "55.21525699994527\n",
      "55.894979499978945\n",
      "56.53373309993185\n",
      "57.153721699956805\n",
      "57.89134349999949\n",
      "58.699312999960966\n",
      "59.4441097000381\n",
      "60.52551109995693\n",
      "61.27933649998158\n",
      "61.88069259992335\n",
      "62.45721339993179\n",
      "63.133192499983124\n",
      "0.617346299928613\n",
      "1.8996201999252662\n",
      "2.561720300000161\n",
      "3.342121099936776\n",
      "3.9596127999247983\n",
      "4.612696999916807\n",
      "5.202970699989237\n",
      "5.83700709999539\n",
      "6.487889499985613\n",
      "7.132641299976967\n",
      "7.833635599934496\n",
      "8.460482099908404\n",
      "9.139458399964496\n",
      "9.750935199903324\n",
      "10.41189290001057\n",
      "11.14142100000754\n",
      "11.735690900008194\n",
      "12.318777099950239\n",
      "12.991992599912919\n",
      "13.610898399958387\n",
      "14.276736999978311\n",
      "14.940934899961576\n",
      "15.605767900007777\n",
      "16.229013399919495\n",
      "16.888142799958587\n",
      "17.548686199937947\n",
      "18.17741969996132\n",
      "18.93987699993886\n",
      "19.80585709994193\n",
      "20.765780399902724\n",
      "21.515999599942006\n",
      "22.243770399945788\n",
      "22.994602899998426\n",
      "23.834389099967666\n",
      "24.58093099994585\n",
      "25.264071599929594\n",
      "25.85421509994194\n",
      "26.473918200004846\n",
      "27.290876899962313\n",
      "27.983104499988258\n",
      "28.834835199988447\n",
      "29.71677830000408\n",
      "30.655297499964945\n",
      "31.84055119997356\n",
      "32.72220019996166\n",
      "33.65530559991021\n",
      "34.483376599964686\n",
      "35.16631239990238\n",
      "35.87787879991811\n",
      "37.20017480000388\n",
      "37.85343139991164\n",
      "38.67455869994592\n",
      "39.34272640000563\n",
      "40.11263709992636\n",
      "40.8733324999921\n",
      "41.54257289995439\n",
      "42.21607209998183\n",
      "42.94828759995289\n",
      "43.634812199976295\n",
      "44.638707499951124\n",
      "45.352815499994904\n",
      "46.05585369991604\n",
      "46.72096859989688\n",
      "47.405338699929416\n",
      "48.012106999987736\n",
      "48.58118889993057\n",
      "49.16509599995334\n",
      "49.787507199915126\n",
      "50.50575049989857\n",
      "51.18563439999707\n",
      "51.852356099989265\n",
      "52.55819189990871\n",
      "53.25908879993949\n",
      "53.94700219994411\n",
      "54.725327499909326\n",
      "55.42705419997219\n",
      "56.04786629998125\n",
      "56.63102480000816\n",
      "57.248706199927256\n",
      "57.90573110000696\n",
      "58.6243744000094\n",
      "59.37505399994552\n",
      "60.251637899898924\n",
      "61.04168909997679\n",
      "62.06859669997357\n",
      "62.8745471999282\n",
      "63.90343159995973\n",
      "66.59241299994756\n",
      "67.98545259993989\n",
      "68.66352729999926\n",
      "69.40462939999998\n",
      "0.8275246999692172\n",
      "2.3763297999976203\n",
      "3.1230532999616116\n",
      "3.950335199944675\n",
      "4.974696599994786\n",
      "5.872729799943045\n",
      "7.088473199983127\n",
      "8.183629799983464\n",
      "9.521179000032134\n",
      "10.692327999975532\n",
      "11.419289799989201\n",
      "12.089026700006798\n",
      "12.865186500013806\n",
      "13.632272399961948\n",
      "14.3761877999641\n",
      "15.025030700024217\n",
      "15.68451259995345\n",
      "16.7194606999401\n",
      "17.444168300018646\n",
      "18.162435399950482\n",
      "18.936999000026844\n",
      "19.702166700037196\n",
      "20.384645899990574\n",
      "21.080221300013363\n",
      "21.790081099956296\n",
      "22.564978700014763\n",
      "23.260640499996953\n",
      "23.965902199968696\n",
      "24.60374050005339\n",
      "25.357357500004582\n",
      "26.129003299982287\n",
      "26.934785799938254\n",
      "27.787918100017123\n",
      "29.214335400029086\n",
      "30.168581299949437\n",
      "30.885277400026098\n",
      "31.747132999938913\n",
      "32.559148799977265\n",
      "33.384508099989034\n",
      "35.0118775999872\n",
      "35.71046159998514\n",
      "36.45277450000867\n",
      "37.16275619994849\n",
      "37.8196098000044\n",
      "38.479700200026855\n",
      "39.22509419999551\n",
      "39.890912499977276\n",
      "40.5319258000236\n",
      "41.2262095999904\n",
      "42.57968059997074\n",
      "43.318918099976145\n",
      "44.12563110003248\n",
      "44.881276099942625\n",
      "45.51258219999727\n",
      "46.151433199993335\n",
      "46.788722299970686\n",
      "47.485432100016624\n",
      "48.16050170001108\n",
      "48.90893060003873\n",
      "50.116621599998325\n",
      "50.83417309995275\n",
      "51.92735240003094\n",
      "52.77217729995027\n",
      "53.57557680003811\n",
      "54.439747700002044\n",
      "55.18030440004077\n",
      "56.2050119000487\n",
      "56.99811040004715\n",
      "57.70856940001249\n",
      "59.23410939995665\n",
      "59.94366089999676\n",
      "60.74421869998332\n",
      "62.26073129998986\n",
      "63.000651499954984\n",
      "63.729622400016524\n",
      "64.46514760004357\n",
      "65.21928229997866\n",
      "65.97241090005264\n",
      "66.6508984999964\n",
      "67.32148150005378\n",
      "67.97042369993869\n",
      "68.60106200003065\n",
      "69.35785010003019\n",
      "70.07304639997892\n",
      "70.93234139995184\n",
      "71.6913263000315\n",
      "72.36027970002033\n",
      "73.0557954000542\n",
      "73.71642469998915\n",
      "74.27706250001211\n",
      "74.95921500003897\n",
      "0.5741589000681415\n",
      "1.806062199990265\n",
      "2.475856300094165\n",
      "3.1023407999891788\n",
      "3.700788800022565\n",
      "4.5043122000060976\n",
      "5.65914550004527\n",
      "6.619350400054827\n",
      "7.35672300006263\n",
      "8.040529899997637\n",
      "8.733764600008726\n",
      "9.425905400072224\n",
      "10.160107200033963\n",
      "10.828896200051531\n",
      "11.490710700047202\n",
      "12.112099800026044\n",
      "12.809925200068392\n",
      "13.480729300063103\n",
      "14.134244700078852\n",
      "14.756228700047359\n",
      "15.501488300040364\n",
      "16.160533600021154\n",
      "16.8165042999899\n",
      "17.604683200013824\n",
      "18.285340600064956\n",
      "19.07255740009714\n",
      "19.999972000019625\n",
      "20.852074000053108\n",
      "21.58272330008913\n",
      "22.29997050005477\n",
      "23.04294070007745\n",
      "23.82225990004372\n",
      "24.555335400043987\n",
      "25.36375310004223\n",
      "26.275836699991487\n",
      "27.15356890007388\n",
      "27.904006300028414\n",
      "29.286678100004792\n",
      "30.3450610000873\n",
      "31.220413300092332\n",
      "32.05028730002232\n",
      "32.894760100054555\n",
      "33.56269120005891\n",
      "34.21040980005637\n",
      "34.83270030003041\n",
      "35.47239740006626\n",
      "36.12950440007262\n",
      "36.83789209998213\n",
      "37.55455910007004\n",
      "38.91574900003616\n",
      "39.93244740006048\n",
      "40.92548209999222\n",
      "41.88226650003344\n",
      "43.646268900018185\n",
      "44.69047270005103\n",
      "46.26243670005351\n",
      "47.98755920003168\n",
      "49.87479490006808\n",
      "51.21523710002657\n",
      "52.241898700012825\n",
      "53.071417700033635\n",
      "53.80084580008406\n",
      "54.4909917000914\n",
      "55.133037400082685\n",
      "55.85273080004845\n",
      "56.71790849999525\n",
      "57.52991480007768\n",
      "58.40746000001673\n",
      "59.23528960009571\n",
      "59.89950410008896\n",
      "60.517519399989396\n",
      "61.19516110001132\n",
      "61.97130289999768\n",
      "62.607402199995704\n",
      "63.317812200053595\n",
      "63.99412130005658\n",
      "64.65835839998908\n",
      "65.34724650008138\n",
      "65.98414180008695\n",
      "66.66598799999338\n",
      "67.3300264000427\n",
      "68.00459860009141\n",
      "68.66309560008813\n",
      "69.34472240007017\n",
      "69.94334090000484\n",
      "70.66091440001037\n",
      "71.43846980005037\n",
      "72.19262570003048\n",
      "72.88291410007514\n",
      "73.55004470003769\n",
      "74.27456330007408\n",
      "0.5564607999986038\n",
      "1.8157358999596909\n",
      "2.424149199970998\n",
      "3.094789299997501\n",
      "3.7144845000002533\n",
      "4.351152900024317\n",
      "4.978775899973698\n",
      "5.7300353000173345\n",
      "6.357406200026162\n",
      "7.049033300019801\n",
      "7.814355099922977\n",
      "8.489071600022726\n",
      "9.372293299995363\n",
      "10.184766000020318\n",
      "10.972688099951483\n",
      "11.808697999920696\n",
      "12.827968599973246\n",
      "13.748648599954322\n",
      "14.66241109999828\n",
      "15.340724800014868\n",
      "16.040360999992117\n",
      "16.740379599970765\n",
      "17.377387800021097\n",
      "18.112501599942334\n",
      "18.70527159993071\n",
      "19.43577159999404\n",
      "20.137009599944577\n",
      "21.232136499951594\n",
      "21.839110299944878\n",
      "22.442100499989465\n",
      "23.108135999995284\n",
      "23.867781599983573\n",
      "24.619327199994586\n",
      "25.331228900002316\n",
      "26.196231100009754\n",
      "26.85638829995878\n",
      "27.806548499967903\n",
      "28.56781899998896\n",
      "29.271570999990217\n",
      "29.991350800031796\n",
      "30.77554499998223\n",
      "31.60361340001691\n",
      "32.35137189994566\n",
      "33.175612499937415\n",
      "34.01786689995788\n",
      "34.77518719993532\n",
      "35.54556809994392\n",
      "36.34525819995906\n",
      "37.2607669000281\n",
      "39.05727330001537\n",
      "39.875166499987245\n",
      "40.57569099997636\n",
      "41.673837999929674\n",
      "42.940326099982485\n",
      "44.05508159997407\n",
      "45.399320899974555\n",
      "47.586930399993435\n",
      "48.55351090000477\n",
      "49.514113000012\n",
      "50.22936420002952\n",
      "51.31868409994058\n",
      "52.088164799963124\n",
      "52.809881199966185\n",
      "53.47225789993536\n",
      "54.376762000028975\n",
      "55.280419199960306\n",
      "56.38030780002009\n",
      "57.40220280003268\n",
      "58.249348799930885\n",
      "60.756480899988674\n",
      "61.58584509999491\n",
      "62.69517469999846\n",
      "63.812315199989825\n",
      "65.435048299958\n",
      "66.53700769995339\n",
      "67.49057879997417\n",
      "71.1801933000097\n",
      "72.14672580000479\n",
      "73.1357669000281\n",
      "75.48705689993221\n",
      "79.00310859992169\n",
      "80.83475929999258\n",
      "82.07651799998712\n",
      "83.38547129998915\n",
      "84.79102769994643\n",
      "86.1220887999516\n",
      "86.90793280000798\n",
      "87.73960780003108\n",
      "89.56940689997282\n",
      "90.28407109994441\n",
      "91.04618529998697\n",
      "0.6471870999084786\n",
      "11.145871699904092\n",
      "12.303080399986356\n",
      "13.355837399954908\n",
      "14.39850419992581\n",
      "16.11470479995478\n",
      "17.086497999960557\n",
      "18.183494800003245\n",
      "19.016757200006396\n",
      "19.737300199922174\n",
      "20.39029089990072\n",
      "21.131561199901626\n",
      "22.126329599996097\n",
      "22.984850899898447\n",
      "23.990859899902716\n",
      "24.90293689991813\n",
      "25.69139979989268\n",
      "26.77684710000176\n",
      "28.063237499911338\n",
      "28.950716799939983\n",
      "29.691313699935563\n",
      "30.62449449999258\n",
      "41.17886159999762\n",
      "47.35370849992614\n",
      "54.149128899909556\n",
      "58.129960599937476\n",
      "60.597505199955776\n",
      "61.66515989997424\n",
      "63.02435839991085\n",
      "63.81309849990066\n",
      "64.57494289998431\n",
      "65.62188629992306\n",
      "66.35138279991224\n",
      "67.64787479990628\n",
      "68.3945050999755\n",
      "69.117628899985\n",
      "69.77938219998032\n",
      "70.47426199994516\n",
      "71.12470489996485\n",
      "71.71419809991494\n",
      "72.34644529991783\n",
      "73.03182379994541\n",
      "73.8527947999537\n",
      "74.65829709998798\n",
      "75.30471199995372\n",
      "76.05742989992723\n",
      "76.79744140000548\n",
      "77.4932712999871\n",
      "78.87509779992979\n",
      "80.09549989993684\n",
      "80.87305910000578\n",
      "81.67580269998871\n",
      "83.569772799965\n",
      "84.28487949992996\n",
      "90.14426529989578\n",
      "94.92394459992647\n",
      "97.9816474999534\n",
      "99.55069859989453\n",
      "111.49327029997949\n",
      "112.8366600999143\n",
      "113.70566380000673\n",
      "114.78819019999355\n",
      "115.7595086999936\n",
      "116.42994899989571\n",
      "116.99245199991856\n",
      "117.76300269993953\n",
      "118.59411559998989\n",
      "119.9620160999475\n",
      "120.68390459998045\n",
      "121.40501989994664\n",
      "121.90962519997265\n",
      "122.48529389989562\n",
      "123.06349559989758\n",
      "124.03683569992427\n",
      "124.68690529989544\n",
      "125.27065149997361\n",
      "125.78788299998268\n",
      "126.30482979991939\n",
      "126.88952450000215\n",
      "127.37288429995533\n",
      "127.98596299998462\n",
      "128.73328829999082\n",
      "129.66011219995562\n",
      "130.45828879997134\n",
      "131.2303522999864\n",
      "131.93831869994756\n",
      "132.42721209989395\n",
      "133.14007329999004\n",
      "133.70543329999782\n",
      "134.18354959995486\n",
      "135.19754639989696\n",
      "0.6554027000674978\n",
      "1.8908511000918224\n",
      "2.3935537000652403\n",
      "2.9740250000031665\n",
      "3.4796391000272706\n",
      "4.051503700087778\n",
      "4.6342949999962\n",
      "5.178274300065823\n",
      "5.812271000002511\n",
      "6.391140300082043\n",
      "6.925333200022578\n",
      "7.4804737999802455\n",
      "8.015403900062665\n",
      "8.547486700001173\n",
      "9.125513800070621\n",
      "9.780110000050627\n",
      "10.416027400060557\n",
      "10.973769300035201\n",
      "11.755656199995428\n",
      "12.45512050006073\n",
      "13.021046900073998\n",
      "13.58275900001172\n",
      "14.121732200030237\n",
      "14.639352600090206\n",
      "15.178706200094894\n",
      "15.69721400004346\n",
      "16.207597500062548\n",
      "16.70948150008917\n",
      "17.183200400089845\n",
      "17.68129430001136\n",
      "18.225664900033735\n",
      "18.83927840006072\n",
      "19.41286190005485\n",
      "20.03090910008177\n",
      "20.491590399993584\n",
      "20.988764900015667\n",
      "21.629061700077727\n",
      "22.158486400032416\n",
      "22.774271100061014\n",
      "23.263474700041115\n",
      "23.817732600029558\n",
      "24.359219300094992\n",
      "24.93916980002541\n",
      "25.448119100066833\n",
      "26.02231680008117\n",
      "26.618322400026955\n",
      "27.162677200045437\n",
      "27.788116000010632\n",
      "28.412500300095417\n",
      "29.684805900091305\n",
      "30.381901500048116\n",
      "31.863212600001134\n",
      "32.619178600027226\n",
      "33.27974939998239\n",
      "33.93677949998528\n",
      "34.81964000000153\n",
      "35.394395900075324\n",
      "36.21625579998363\n",
      "36.921716100070626\n",
      "37.62905620003585\n",
      "38.232696900027804\n",
      "39.01553360000253\n",
      "39.568514200043865\n",
      "40.239531100029126\n",
      "41.057452699984424\n",
      "41.624092300073244\n",
      "42.13212329999078\n",
      "42.707877599983476\n",
      "43.30005419999361\n",
      "43.89662610006053\n",
      "44.524684000061825\n",
      "45.12174380000215\n",
      "45.67272580007557\n",
      "46.17622350004967\n",
      "47.088661600020714\n",
      "47.67078440007754\n",
      "48.316013600095175\n",
      "48.916793600074016\n",
      "49.4992448000703\n",
      "50.4450882000383\n",
      "51.4596523999935\n",
      "52.0393655000953\n",
      "52.58175480004866\n",
      "53.17224260000512\n",
      "53.69019069999922\n",
      "54.375995100010186\n",
      "55.0039598000003\n",
      "55.66044830007013\n",
      "56.212890100083314\n",
      "56.994068300002255\n",
      "57.83214140008204\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "############### EMRIL V 1.3 ####################\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from river.tree import HoeffdingTreeClassifier\n",
    "\n",
    "from time import perf_counter\n",
    "from sklearn import clone\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import statistics\n",
    "from decimal import Decimal\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn import preprocessing\n",
    "from numpy import sqrt\n",
    "import matplotlib.ticker as mticker\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math \n",
    "from numpy.linalg import norm\n",
    "import statistics\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial  import distance_matrix\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from river import tree\n",
    "\n",
    "\n",
    "# Assuming you want to use River's HoeffdingTreeClassifier\n",
    "clf = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "# Example of usage with stream-based data\n",
    "clfs = [clf]\n",
    "clfs_label = [\"Hoeffding Tree Classifier\"]\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', '{:.8f}'.format)\n",
    "#np.set_printoptions(suppress=True)\n",
    "#np.set_printoptions(threshold=1000000000)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def __get_coefficients(y_true, y_pred_a, y_pred_b):\n",
    "    a, b, c, d = 0, 0, 0, 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if y_pred_a[i] == y_true[i] and y_pred_b[i] == y_true[i]:\n",
    "            a = a + 1\n",
    "        elif y_pred_a[i] != y_true[i] and y_pred_b[i] == y_true[i]:\n",
    "            b = b + 1\n",
    "        elif y_pred_a[i] == y_true[i] and y_pred_b[i] != y_true[i]:\n",
    "            c = c + 1\n",
    "        else:\n",
    "            d = d + 1\n",
    " \n",
    "    return a, b, c, d\n",
    "\n",
    "def q_statistics(y_true, y_pred_a, y_pred_b):\n",
    "    a, b, c, d = __get_coefficients(y_true, y_pred_a, y_pred_b)\n",
    "    q = float(a * d - b * c) / (a * d + b * c)\n",
    "    return q\n",
    "\n",
    "def double_fault_measure(y_true, y_pred_a, y_pred_b):\n",
    "    a, b, c, d = __get_coefficients(y_true, y_pred_a, y_pred_b)\n",
    "    df = float(d) / (a + b + c + d)\n",
    "    return df\n",
    "\n",
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    \n",
    "    # traverse in the string  \n",
    "    for ele in s: \n",
    "        str1 += str(ele)+ \"-\" \n",
    "    \n",
    "    # return string  \n",
    "    return str1 \n",
    "# normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n",
    "def pltcolor(lst):\n",
    "    cols=[]\n",
    "    for l in lst:\n",
    "        if l==0:\n",
    "            cols.append('blue')\n",
    "        elif l==1:\n",
    "            cols.append('red')\n",
    "    return cols\n",
    "\n",
    "\n",
    "def detect_overlap(data_min,data_maj,n_features):\n",
    "    fishers = []\n",
    "    found = 0\n",
    "    max_f1 = 0\n",
    "    max_feature_index = 0\n",
    "    Xy_up = data_min\n",
    "    Xy_down = data_maj\n",
    "    frames = [Xy_up,Xy_down]\n",
    "    Xy_d = pd.concat(frames)\n",
    "    f_data_up_means = Xy_up.mean()\n",
    "    f_data_down_means= Xy_down.mean()\n",
    "    f_data_up_vars = Xy_up.var()\n",
    "    f_data_down_vars =Xy_down.var()\n",
    "    for i in range(n_features):\n",
    "        mean_up = f_data_up_means[i]\n",
    "        mean_down = f_data_down_means[i]\n",
    "        var_up = f_data_up_vars[i]\n",
    "        var_down = f_data_down_vars[i]\n",
    "        fisher = ((mean_up-mean_down)**2) / (var_up + var_down)\n",
    "        fishers.append([i,round(fisher,5),round(mean_up,5),round(mean_down,5)])\n",
    "        if(fisher>max_f1) :\n",
    "            max_f1 = fisher\n",
    "            max_feature_index = i\n",
    "\n",
    "    max_index= max_feature_index + 1\n",
    "    #print(\"Actual Max:\",max_f1)\n",
    "    max_f1 = 1/(1+max_f1)   # push between (0,1]\n",
    "    #print(\"Transformed Max:\",max_f1)       \n",
    "    fishers=sorted(fishers,key=lambda x: x[1], reverse=False)\n",
    "    return round(max_f1,5), fishers\n",
    "\n",
    "def update_minority_buffer(X,y,n_features):\n",
    "    global minority_buffer_x\n",
    "    global minority_buffer_y \n",
    "    global w\n",
    "    global df_buffer_x\n",
    "    global min_life_max\n",
    "    \n",
    "    decrease_life()   \n",
    "    remove_zero_life_rows()\n",
    "    for n in range (0, len(X)):\n",
    "        df_buffer_x = df_buffer_x.append(X.iloc[n])\n",
    "        df_buffer_x.iloc[-1,df_buffer_x.columns.get_loc(\"life\")] = min_life_max\n",
    "        df_buffer_x.iloc[-1,df_buffer_x.columns.get_loc(\"recall_weight\")] = 1\n",
    "        df_buffer_x.iloc[-1,df_buffer_x.columns.get_loc(\"total_weight\")] = 1\n",
    "    recalculate_total_weight()\n",
    "\n",
    "def decrease_life():\n",
    "    global df_buffer_x\n",
    "    global min_life_decay_factor    \n",
    "    df_buffer_x['life'] -= min_life_decay_factor\n",
    "   # print(df_buffer_x)\n",
    "\n",
    "def update_recall_weight(weight):\n",
    "    global df_buffer_x\n",
    "    global min_life_max\n",
    "    df_buffer_x.loc[df_buffer_x.life == min_life_max, 'recall_weight'] = weight   \n",
    "    #print(df_buffer_x)\n",
    "   # sys.exit()\n",
    "    \n",
    "def recalculate_total_weight():\n",
    "    global df_buffer_x\n",
    "    global min_life_max\n",
    "    df_buffer_x['total_weight'] = 0.5* df_buffer_x['life'] + 0.5* df_buffer_x['recall_weight']   \n",
    "    #print(df_buffer_x)\n",
    "    \n",
    "#performs random oversampling  \n",
    "def resample_from_buffer(X,y,samples_to_add):\n",
    "   # print(X)\n",
    "    global df_buffer_x\n",
    "    temp_X = X\n",
    "    temp_y = y\n",
    "    temp_y = temp_y.iloc[0:0]\n",
    "    temp_X = temp_X.iloc[0:0]\n",
    "    try:\n",
    "        to_add_for_one_element = round(samples_to_add/len(df_buffer_x),0)\n",
    "        #print(\"to_add_for_one_element:\",to_add_for_one_element)\n",
    "        min_buf_copy = df_buffer_x\n",
    "        min_buf_copy = min_buf_copy.drop(['life', 'recall_weight','total_weight'], axis=1)\n",
    "        #print(len(min_buf_copy))\n",
    "        for v in range (0,len(min_buf_copy)):\n",
    "            #print(X.iloc[[v]])\n",
    "            for c in range(0,int(to_add_for_one_element)):\n",
    "                #print(\"adding resample\")\n",
    "                temp_X = temp_X.append(min_buf_copy.iloc[[v]])\n",
    "                temp_y = temp_y.append({'class': 1}, ignore_index=True)\n",
    "                #print(len(temp_X))\n",
    "        #print(temp_X)\n",
    "        #print(\"resample from buffer--return rows\")\n",
    "        #print(temp_X)\n",
    "        #print(temp_y)\n",
    "    except:\n",
    "        a = 1 #do nothing\n",
    "    \n",
    "   # print(len(temp_X))\n",
    "    #print(len(temp_y))\n",
    "    return temp_X,temp_y\n",
    "\n",
    "def remove_zero_life_rows():\n",
    "    global df_buffer_x\n",
    "    #print(\"before:\",len(df_buffer_x))  \n",
    "    df_buffer_x = df_buffer_x[df_buffer_x['total_weight'] >= 0.50]\n",
    "    #print(\"after:\",len(df_buffer_x))\n",
    "\n",
    "\n",
    "#performs random oversampling  \n",
    "def get_weighted_buffer_data(X,y):\n",
    "    global df_buffer_x\n",
    "    temp_X = X\n",
    "    temp_y = y\n",
    "    temp_y = temp_y.iloc[0:0]\n",
    "    temp_X = temp_X.iloc[0:0]\n",
    "    min_buf_copy = df_buffer_x #.loc[df_buffer_x['total_weight'] >= 0.50] \n",
    "    min_buf_copy = min_buf_copy.drop(['life', 'recall_weight','total_weight'], axis=1)    \n",
    "    for v in range (0,len(min_buf_copy)):\n",
    "            temp_X = temp_X.append(min_buf_copy.iloc[[v]])\n",
    "            temp_y = temp_y.append({'class': 1}, ignore_index=True)    \n",
    "    return temp_X,temp_y\n",
    "\n",
    "#code for fixing clusters in the data\n",
    "#user class_to_process=1 for minority space -- creates equal size clusters.\n",
    "#for majority, set class_to_process=0, performs sampling within clusters without making them equal size.\n",
    "def fix_disjuncts(X,y,samples_to_add,class_to_process,DontAddToBuffer,n_features):\n",
    "    global disjuncts\n",
    "    global output_folder\n",
    "    global disjuncts_threshold\n",
    "    global arr_ord_cols\n",
    "    global minority_buffer_x\n",
    "    global minority_buffer_y\n",
    "    global w\n",
    "    global df_buffer_x\n",
    "    global disable_buffer\n",
    "    #if minority is less than 5% in the batch \n",
    "    #then use minority buffer to do get data.    \n",
    "    min_min_count = int(w*0.05) #we need atleast 5% samples for clustering\n",
    "    \n",
    "    #If minority, see if requires samples from buffer\n",
    "    if(disable_buffer == False):\n",
    "        if(class_to_process == 1):\n",
    "            if(DontAddToBuffer == False):\n",
    "                update_minority_buffer(X,y,n_features)\n",
    "                #print(\"buffer updated !\")\n",
    "\n",
    "            if(len(X) < min_min_count):\n",
    "                #print(\"**********************using buffer or resample from buffer*********************\")\n",
    "                if(len(df_buffer_x) < min_min_count):\n",
    "                    return resample_from_buffer(X,y,samples_to_add)\n",
    "                else:\n",
    "                    X,y = get_weighted_buffer_data(X,y)\n",
    "\n",
    "\n",
    "\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    if(len(X) < 10):\n",
    "        return X,y\n",
    "    \n",
    "    data_scaled = X\n",
    "    n_samples, n_features = X.shape\n",
    "    try:\n",
    "        data_scaled = preprocessing.scale(X)\n",
    "    except:\n",
    "        return X,y\n",
    "    linked = linkage(data_scaled, 'average')\n",
    "    last = linked[-10:, 2]\n",
    "    last_rev = last[::-1]\n",
    "    idxs = np.arange(1, len(last) + 1)\n",
    "    accele = np.diff(last, 2)  # 2nd derivative of the distances\n",
    "    accele_rev = accele[::-1]\n",
    "    k = accele_rev.argmax() + 2  # if idx 0 is the max of this we want 2 clusters\n",
    "\n",
    "    model = AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto', connectivity=None, linkage='average', memory=None, n_clusters=k)\n",
    "    y_hc=model.fit_predict(X)\n",
    "    aggloclust=model.fit(X)\n",
    "    (unique, counts) = np.unique(aggloclust.labels_, return_counts=True)\n",
    "    frequencies = np.asarray((unique, counts)).T\n",
    "    frequencies = frequencies[np.argsort(frequencies[:, 1])[::-1]]\n",
    "    arr_cumsum = np.cumsum(frequencies,axis=0)\n",
    "    cumsum = arr_cumsum[:,1]\n",
    "    arr_sum_cumsum = np.sum(frequencies,axis=0)\n",
    "    arr_clusters = []\n",
    "    sum_cumsum = arr_sum_cumsum[1]\n",
    "    for i in range(len(arr_cumsum)):\n",
    "        val = cumsum[i]\n",
    "        arr_clusters.append(frequencies[i,0])\n",
    "\n",
    "    \n",
    "    arr_y_frames  = []\n",
    "    arr_x_frames  = []\n",
    "    cluster1_count =0\n",
    "    df_x1 = []\n",
    "    df_y1 = []\n",
    "    \n",
    "    disjuncts = len(arr_clusters)\n",
    "    if(disjuncts<disjuncts_threshold):\n",
    "        return X,y\n",
    "    \n",
    "    valid_clusters =0\n",
    "    for i in range(len(arr_clusters)):\n",
    "        arr_indexes = ((np.where(y_hc == int(arr_clusters[i]))))\n",
    "        df_y = y.loc[y.index[arr_indexes]]\n",
    "        if(len(df_y) > 2):\n",
    "            valid_clusters += 1\n",
    "    if(valid_clusters == 0):\n",
    "        return X,y\n",
    "    \n",
    "    each_cluster_addition = int(np.round(samples_to_add / valid_clusters ))  \n",
    "    for i in range(len(arr_clusters)):\n",
    "            arr_indexes = ((np.where(y_hc == int(arr_clusters[i]))))\n",
    "            df_x = X.loc[X.index[arr_indexes]]\n",
    "            df_y = y.loc[y.index[arr_indexes]]\n",
    "            \n",
    "            \n",
    "            if(len(df_x) <3):\n",
    "                continue\n",
    "            \n",
    "            to_add = 0\n",
    "            if(i==0):\n",
    "                cluster1_count = len(df_x)\n",
    "                to_add = each_cluster_addition\n",
    "            else:\n",
    "                to_add = each_cluster_addition\n",
    "                \n",
    "                #code to make equal size clusters in minority\n",
    "                if(class_to_process == 1):\n",
    "                    current_cluster_count = len(df_x)\n",
    "                    to_add += (cluster1_count-current_cluster_count)\n",
    "                   \n",
    "            df_cov = df_x.cov()\n",
    "            df_mean = df_x.mean(axis=0)\n",
    "            try:\n",
    "                new_samples = np.random.multivariate_normal(df_mean, df_cov,to_add)\n",
    "            except:\n",
    "                return X,y\n",
    "            \n",
    "            cols = []\n",
    "            for f in range(1,n_features+1):\n",
    "                cols.append(str(f))\n",
    "            df_new_samples = pd.DataFrame(new_samples,columns=cols)\n",
    "            df_x = pd.concat([df_x.reset_index(drop=True),df_new_samples.reset_index(drop=True)],axis=0)\n",
    "            df_x = df_x.reset_index(drop=True)\n",
    "            if(len(arr_ord_cols)>0):\n",
    "                for h in range (0,len(arr_ord_cols)):\n",
    "                    ix = arr_ord_cols[h]\n",
    "                    df_x[str(ix)] = round(df_x[str(ix)]) \n",
    "            for j in range(0,to_add):\n",
    "                df_y = df_y.append(pd.Series([class_to_process],index=['class']),ignore_index = True) \n",
    "            \n",
    "            df_y = df_y.reset_index(drop=True)            \n",
    "            arr_x_frames.append(df_x)\n",
    "            arr_y_frames.append(df_y)        \n",
    "    \n",
    "    np.set_printoptions(threshold=np.inf)            \n",
    "    modified_X = pd.concat(arr_x_frames)\n",
    "    modified_Y = pd.concat(arr_y_frames)\n",
    "    \n",
    "    modified_X = modified_X.reset_index(drop=True)\n",
    "    modified_Y = modified_Y.reset_index(drop=True)\n",
    "    #print(\"**********</Fix Disjuncts End>************\")\n",
    "    #print(modified_X.shape)\n",
    "    return modified_X,modified_Y    \n",
    "\n",
    "\n",
    "def icrc(X_maj,X_min,y_maj,y_min,n_features,overlap_val,fullFit,ups,downs):\n",
    "    global f1_overlap_value\n",
    "    global overlap_threshold_f1\n",
    "    global imbalance_ratio_threshold\n",
    "    ##################### Update Imbalance status of current window\n",
    "    is_imbalance = False\n",
    "    ir = 0\n",
    "    if(ups ==0 or downs ==0):\n",
    "        ir = imbalance_ratio_threshold + 1\n",
    "    elif(ups > downs):\n",
    "        ir = ups/downs\n",
    "    elif(ups < downs):\n",
    "        ir = downs/ups\n",
    "    elif(ups == downs):\n",
    "        ir = 1\n",
    "\n",
    "    if(ir>=imbalance_ratio_threshold):\n",
    "        is_imbalance = True\n",
    "    ########################################\n",
    "\n",
    "    #is_imbalance = False\n",
    "    if(is_imbalance == False):\n",
    "        frames = [X_min,X_maj]\n",
    "        modified_X = pd.concat(frames)\n",
    "        frames = [y_min,y_maj]\n",
    "        modified_Y = pd.concat(frames).replace('UP',1).replace('DOWN',0) \n",
    "        return modified_X.to_numpy(),modified_Y.to_numpy().reshape(-1)\n",
    "\n",
    "    if(is_imbalance==True):\n",
    "        is_overlap = False\n",
    "        fitted_already = False\n",
    "        modified_Xmin,modified_Ymin = fix_disjuncts(X_min,y_min,(len(X_maj)-len(X_min)),1,fullFit,n_features)\n",
    "        modified_Xmaj= X_maj\n",
    "        modified_Ymaj = y_maj\n",
    "        f1_overlap_value = overlap_val\n",
    "        if (f1_overlap_value > overlap_threshold_f1): \n",
    "            is_overlap =  True\n",
    "        if is_overlap:\n",
    "            modified_Xmaj = modified_Xmaj.reset_index(drop=True)\n",
    "            modified_Xmin = modified_Xmin.reset_index(drop=True)\n",
    "            idx_maj = len(modified_Xmaj)\n",
    "            \n",
    "            all_data = pd.concat([modified_Xmaj,modified_Xmin])\n",
    "            a = pdist(all_data,metric='euclidean')\n",
    "            t_l = len(all_data)\n",
    "            d_1 = linkage(a)\n",
    "            \n",
    "            d_2 = pd.DataFrame(d_1,columns=['i1','i2','i3','i4'])\n",
    "            filtered_values = np.where( ((d_2[\"i1\"] < idx_maj) & (d_2[\"i2\"] > idx_maj) & (d_2[\"i2\"] <t_l)  ) | ((d_2[\"i1\"] > idx_maj) & (d_2[\"i1\"] < t_l ) & (d_2[\"i2\"] < idx_maj) ) )\n",
    "            filtered =  d_2.loc[filtered_values]\n",
    "            arr_indexes = filtered.iloc[:,0].to_numpy() \n",
    "            to_remove = int(len(arr_indexes)*disjunct_threshold_perc_maj)            \n",
    "            drop_these = (arr_indexes[0:to_remove])\n",
    "            modified_Xmaj.drop(index=drop_these,inplace=True)\n",
    "            modified_Ymaj = modified_Ymaj.iloc[to_remove:]\n",
    "        if(len(modified_Xmin) > len(modified_Xmaj)):\n",
    "            modified_Xmaj,modified_Ymaj = fix_disjuncts(modified_Xmaj,modified_Ymaj,(len(modified_Xmin)-len(modified_Xmaj)),0,fullFit,n_features)\n",
    "\n",
    "        frames = [modified_Xmin,modified_Xmaj]\n",
    "        modified_X = pd.concat(frames)\n",
    "        frames = [modified_Ymin,modified_Ymaj]\n",
    "        modified_Y = pd.concat(frames).replace('UP',1).replace('DOWN',0) \n",
    "        \n",
    "    return modified_X.to_numpy(),modified_Y.to_numpy().reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "class DetectorClassifier:\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for xi, yi in zip(X, y):\n",
    "            if not isinstance(self.clf, HoeffdingTreeClassifier):\n",
    "              raise TypeError(\"Classifier is not a HoeffdingTreeClassifier from river\")\n",
    "\n",
    "              self.clf = self.clf.learn_one(dict(enumerate(xi)), yi)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y):\n",
    "        # Incremental learning: this will also use learn_one method\n",
    "        for xi, yi in zip(X, y):\n",
    "            self.clf.learn_one(dict(enumerate(xi)), yi)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for xi in X:\n",
    "            xi_dict = dict(enumerate(xi))\n",
    "            pred = self.clf.predict_one(xi_dict)\n",
    "            preds.append(pred if pred is not None else 0)  # fallback for None\n",
    "        return np.asarray(preds)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probas = []\n",
    "        for xi in X:\n",
    "            xi_dict = dict(enumerate(xi))\n",
    "            proba_dict = self.clf.predict_proba_one(xi_dict)\n",
    "            # Ensure class order [0, 1]\n",
    "            probas.append([proba_dict.get(0, 0.0), proba_dict.get(1, 0.0)])\n",
    "        return np.asarray(probas)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return np.mean(preds == y)\n",
    "\n",
    "\n",
    "  \n",
    "def prequential(window_size,Xy,X, y, clf,n_features,overlap_threshold,imbalance_ratio_threshold,disjunct_threshold_perc_maj,file_out_prefix, n_train=1):\n",
    "    \n",
    "    \"\"\"Prequential Evaluation: instances are first used to test, and then to train\n",
    "    :return the label predictions for each test instance, and the associated running time\n",
    "    \"\"\"\n",
    "    first_weights_flag = False\n",
    "    \n",
    "    arr_clf = []\n",
    "    arr_clf_temp_to_use = []\n",
    "    arr_weights = []\n",
    "    arr_recall0_cw = []\n",
    "    arr_recall1_cw = []\n",
    "    \n",
    "    a= 0.00001\n",
    "    start = timer()\n",
    "\n",
    "    global arr_elapsedtime\n",
    "    global restart_threshold\n",
    "    global arr_recall_0\n",
    "    global arr_recall_1\n",
    "    global output_folder\n",
    "    global maj_weight\n",
    "    global min_weight\n",
    "    global ens_weight\n",
    "    global ensemble_pool_size    \n",
    "    global pruned_ensemble_size\n",
    "    global rl_pruned_ids\n",
    "    global preq_Qtable\n",
    "\n",
    "    preq_Qtable = initialize_q_table(ensemble_pool_size, ensemble_pool_size)\n",
    "    arr_actual_win = []\n",
    "    arr_pred_win = []\n",
    "    arr_roc = []\n",
    "    arr_divs = []\n",
    "    ensemble_tp = 0\n",
    "    ensemble_fp =0\n",
    "    ensemble_fn = 0\n",
    "    ensemble_tn = 0\n",
    "    \n",
    "    \n",
    "    ensemble_correct =0\n",
    "    zeroClassCounter = 0\n",
    "    oneClassCounter = 0\n",
    "    current_correct_0 = 0\n",
    "    current_correct_1 = 0\n",
    "    \n",
    "    current_correct_ensemble_0 = 0\n",
    "    current_correct_ensemble_1 = 0\n",
    "    \n",
    "    predictions = \"\"    \n",
    "    row_num = y.shape[0]   \n",
    "   \n",
    "    # Split an init batch\n",
    "    X_init = X[0:n_train]\n",
    "    y_init = y[0:n_train]\n",
    "    \n",
    "    # Used for training and evaluation\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    Xy_train = Xy\n",
    "    \n",
    "        \n",
    "    ensemble_preds = np.zeros(row_num)\n",
    "    current_correct_0_cw = np.zeros(ensemble_pool_size)\n",
    "    current_correct_1_cw = np.zeros(ensemble_pool_size)\n",
    "    recall_0_cw = np.zeros(ensemble_pool_size)\n",
    "    recall_1_cw = np.zeros(ensemble_pool_size)\n",
    "    \n",
    "   \n",
    "    for g in range (0,ensemble_pool_size):\n",
    "        #Create a classifier and add it to the pool\n",
    "        obj_clf = DetectorClassifier(HoeffdingTreeClassifier())\n",
    "        obj_clf = obj_clf.fit(X_init, y_init)\n",
    "        arr_clf.append(obj_clf)\n",
    "        arr_weights.append(1)\n",
    "    \n",
    "    \n",
    "    current_w = 0\n",
    "    window_counter = 0\n",
    "    strProcessing = \"\"\n",
    "    correct_predictions = 0\n",
    "\n",
    "    strout = \"\"\n",
    "    strgmean = \"\"\n",
    "\n",
    "    oneClassCounter_CWindow = 0\n",
    "    zeroClassCounter_CWindow = 0\n",
    "    arr_cw_ens_preds = []\n",
    "    current_correct_0_cw_est = 0\n",
    "    current_correct_1_cw_est = 0\n",
    "    window_recall_0 = 0\n",
    "    window_recall_1 = 0\n",
    "        \n",
    "    for i in range(0, row_num):\n",
    "\n",
    "        current_w += 1\n",
    "        start_time = perf_counter()\n",
    "        arr_preds = []\n",
    "        arr_temp_preds = []\n",
    "        \n",
    "        for n in range(0,len(arr_clf)):\n",
    "            clf = arr_clf[n]\n",
    "            prediction_clf = clf.predict(X_train[i, :].reshape(1, -1))\n",
    "            arr_preds.append(prediction_clf[0])\n",
    "            arr_temp_preds.append(prediction_clf[0])\n",
    "        arr_cw_ens_preds.append(arr_temp_preds)    \n",
    "        #sys.exit()\n",
    "       \n",
    "        strout += \"------------\\n\"\n",
    "        estimators_arr = []\n",
    "        for n in range(0,len(arr_clf)):\n",
    "            estimators_arr.append((\"HT-\" + str(n), arr_clf[n]))\n",
    "        \n",
    "       \n",
    "        df_estimators_arr = pd.DataFrame(arr_clf)\n",
    "        df_weights_arr = pd.DataFrame(arr_weights)        \n",
    "        df_weights_arr = df_weights_arr.sort_values(ascending=False,by=df_weights_arr.columns[0])        \n",
    "        arr_clf_temp_to_use = []\n",
    "        estimators_arr_temp = []\n",
    "        arr_weights_temp = []\n",
    "\n",
    "        for h in range(0,len(rl_pruned_ids)) :\n",
    "            try:\n",
    "                indexx = rl_pruned_ids[h].astype(int)\n",
    "            except:\n",
    "                indexx = rl_pruned_ids[h]\n",
    "\n",
    "            index_original = df_weights_arr.iloc[[h]].index.values[0]\n",
    "            arr_clf_temp_to_use.append(arr_clf[indexx])\n",
    "            estimators_arr_temp.append((\"HT-\" + str(index_original), arr_clf[indexx]))\n",
    "            arr_weights_temp.append(arr_weights[indexx])\n",
    "        \n",
    "        if(len(arr_clf_temp_to_use) == 0):\n",
    "            for h in range(0,len(arr_clf)) :               \n",
    "                index_original = df_weights_arr.iloc[[h]].index.values[0]\n",
    "                arr_clf_temp_to_use.append(arr_clf[index_original])\n",
    "                estimators_arr_temp.append((\"HT-\" + str(index_original), arr_clf[index_original]))\n",
    "                arr_weights_temp.append(arr_weights[index_original])\n",
    "       \n",
    "        pred = 0\n",
    "        try:\n",
    "            eclf = VotingClassifier(estimators = estimators_arr_temp, voting='soft') \n",
    "            eclf.estimators_ = arr_clf_temp_to_use\n",
    "            eclf.le_ = LabelEncoder().fit(np.unique([0, 1]))\n",
    "            pred_proba = eclf.predict_proba(X_train[i, :].reshape(1, -1))\n",
    "            pred = eclf.predict(X_train[i, :].reshape(1, -1))\n",
    "            arr_tempo = pred_proba[0]\n",
    "            arr_pred_win.append(arr_tempo[1])\n",
    "        except:\n",
    "            eclf = VotingClassifier(estimators = estimators_arr_temp, voting='hard') \n",
    "            eclf.estimators_ = arr_clf_temp_to_use\n",
    "            eclf.le_ = LabelEncoder().fit(np.unique([0, 1]))\n",
    "            pred = eclf.predict(X_train[i, :].reshape(1, -1))\n",
    "            if(pred==0):\n",
    "                arr_pred_win.append(0)\n",
    "            if(pred==1):\n",
    "                arr_pred_win.append(1)  \n",
    "        \n",
    "        #print(\"i:\",i)\n",
    "        ensemble_preds[i] = pred\n",
    "        #print(\"ens_size:\",len(ensemble_preds))\n",
    "        #sys.exit()\n",
    "        counter = i+1\n",
    "        lambda_0 = maj_weight#Majority\n",
    "        lambda_1 = min_weight #Minority\n",
    "        \n",
    "        if y_train[i] == 0:\n",
    "            zeroClassCounter += 1\n",
    "            zeroClassCounter_CWindow += 1\n",
    "        else: \n",
    "            oneClassCounter += 1\n",
    "            oneClassCounter_CWindow += 1\n",
    "        correct_found = 0\n",
    "\n",
    "        for n in range(0,len(arr_clf)):\n",
    "            if(y_train[i] == 0 and arr_preds[n] ==0):\n",
    "                current_correct_0_cw[n] = current_correct_0_cw[n]+1\n",
    "            if(y_train[i] == 1 and arr_preds[n] ==1):    \n",
    "                current_correct_1_cw[n] = current_correct_1_cw[n]+1\n",
    "        \n",
    "        correct_found = 0  \n",
    "        y_actual = 0\n",
    "        y_pred = 0\n",
    "        if(y_train[i] ==0 and pred ==0):\n",
    "            correct_found +=1\n",
    "            current_correct_ensemble_0 += 1\n",
    "            current_correct_0_cw_est += 1\n",
    "            ensemble_tn += 1\n",
    "            y_actual = 0\n",
    "            y_pred = 0\n",
    "        if(y_train[i] ==1 and pred == 1):\n",
    "            correct_found +=1\n",
    "            current_correct_ensemble_1 += 1\n",
    "            current_correct_1_cw_est += 1\n",
    "            ensemble_tp += 1\n",
    "            y_actual = 1\n",
    "            y_pred = 1\n",
    "        if(y_train[i] ==1 and pred ==0):\n",
    "            ensemble_fn += 1\n",
    "            y_actual = 1\n",
    "            y_pred = 0\n",
    "        if(y_train[i] ==0 and pred == 1):\n",
    "            ensemble_fp += 1\n",
    "            y_actual = 0\n",
    "            y_pred = 1\n",
    "        if(correct_found ==1):\n",
    "            ensemble_correct += 1\n",
    "            \n",
    "        arr_actual_win.append(y_actual)                   \n",
    "        \n",
    "        \n",
    "        #when the batch is ready / an incomplete batch at the end\n",
    "        if( ( current_w % window_size == 0)  or (current_w != window_size and i == (row_num - w -1)) ):\n",
    "\n",
    "            window_counter += 1\n",
    "            \n",
    "            window_recall_0 = 0\n",
    "            window_recall_1 = 0\n",
    "            if zeroClassCounter_CWindow != 0:\n",
    "                window_recall_0 =  current_correct_0_cw_est / zeroClassCounter_CWindow\n",
    "            if oneClassCounter_CWindow != 0:\n",
    "                window_recall_1 =  current_correct_1_cw_est / oneClassCounter_CWindow\n",
    "            \n",
    "            window_gmean = sqrt(window_recall_0*window_recall_1)\n",
    "            \n",
    "            \n",
    "            update_recall_weight( (lambda_0*window_recall_0) + (lambda_1*window_recall_1))\n",
    "            \n",
    "            #print(\"current window gmean:\",str(window_gmean*100))\n",
    "            arr_gmean.append(window_gmean*100)\n",
    "            arr_recall_0.append(window_recall_0*100)\n",
    "            arr_recall_1.append(window_recall_1*100)\n",
    "            \n",
    "            accuracy = (ensemble_tp+ensemble_tn)/(zeroClassCounter_CWindow+oneClassCounter_CWindow)\n",
    "\n",
    "            arr_actual_win=[]\n",
    "            arr_pred_win = []\n",
    "            arr_cw_ens_preds = []            \n",
    "            \n",
    "            for n in range(0,len(arr_clf)):                    \n",
    "                if zeroClassCounter_CWindow != 0:\n",
    "                    recall_0_cw[n] =  current_correct_0_cw[n] / zeroClassCounter_CWindow                    \n",
    "                else:\n",
    "                    recall_0_cw[n] =  1\n",
    "                    \n",
    "            for n in range(0,len(arr_clf)):\n",
    "                    if oneClassCounter_CWindow != 0:\n",
    "                        recall_1_cw[n] =  current_correct_1_cw[n] / oneClassCounter_CWindow\n",
    "                    else:\n",
    "                        recall_1_cw[n] = 1\n",
    "\n",
    "            arr_weights = [(lambda_0 * recall_0_cw[n]) + (lambda_1 * recall_1_cw[n]) for n in range(len(arr_clf))]\n",
    "\n",
    "            arr_weights = normalize(arr_weights)\n",
    "\n",
    "            oneClassCounter_CWindow = 0\n",
    "            zeroClassCounter_CWindow = 0  \n",
    "            current_correct_0_cw_est = 0\n",
    "            current_correct_1_cw_est = 0\n",
    "            ensemble_tn = 0\n",
    "            ensemble_tp = 0\n",
    "            ensemble_fp = 0\n",
    "            ensemble_fn = 0\n",
    "            \n",
    "            current_correct_0_cw = [0] * len(arr_clf)\n",
    "            current_correct_1_cw = [0] * len(arr_clf)\n",
    "            \n",
    "           \n",
    "            x_preq = X_train[i-(window_size-1):i]\n",
    "            y_preq = y_train[i-(window_size-1):i]\n",
    "\n",
    "            Xy_preq = Xy_train[i-(window_size-1):i]\n",
    "            ups =  np.count_nonzero(y_preq == 1)\n",
    "            downs = np.count_nonzero(y_preq == 0)            \n",
    "\n",
    "            arr_clf_temp = []\n",
    "\n",
    "            ####################### <Overlap Detection> ############################################\n",
    "            #Check overlaps where and send its status to partialfit\n",
    "            cols_str = []\n",
    "            for f in range(1,n_features+1):\n",
    "                cols_str.append(str(f))\n",
    "            cols_str.append('class')\n",
    "            Xy_d = pd.DataFrame(Xy_preq, columns = cols_str)\n",
    "            if(ups < downs):\n",
    "                Xy_min = Xy_d[(Xy_d['class'] == 1)]\n",
    "                Xy_maj = Xy_d[(Xy_d['class'] == 0)]\n",
    "            if(ups>downs):\n",
    "                Xy_min = Xy_d[(Xy_d['class'] == 0 )]\n",
    "                Xy_maj = Xy_d[(Xy_d['class'] == 1 )]\n",
    "\n",
    "            cols = []\n",
    "            for f in range(0,n_features):\n",
    "                cols.append(f)\n",
    "            cols_class = [n_features]\n",
    "            X_min = Xy_min[Xy_min.columns[cols]]\n",
    "            X_maj = Xy_maj[Xy_maj.columns[cols]]\n",
    "            y_min = Xy_min[Xy_min.columns[cols_class]]\n",
    "            y_maj = Xy_maj[Xy_maj.columns[cols_class]]\n",
    "            \n",
    "            frames = [X_min,X_maj]\n",
    "            modified_X = pd.concat(frames)\n",
    "            frames = [y_min,y_maj]\n",
    "            modified_Y = pd.concat(frames)\n",
    "\n",
    "            cols_num = []            \n",
    "            cols_num = list(range(n_features))\n",
    "\n",
    "            m_X = modified_X\n",
    "            m_Y = modified_Y            \n",
    "            m_X.columns = cols_num\n",
    "            m_Y.columns = [0]  \n",
    "            \n",
    "            \n",
    "            overlap_val, fishers = detect_overlap(X_min, X_maj,n_features)   \n",
    "            \n",
    "            ####################### </Drift Detection and Overlap> ############################################\n",
    "            \n",
    "            modified_x,modified_y = icrc(X_maj,X_min,y_maj,y_min,n_features,overlap_val,False,ups,downs)\n",
    "                   \n",
    "            arr_temp_clfs = []\n",
    "            ## Partial Fit the previous classifiers\n",
    "            for n in range(0,len(arr_clf)):\n",
    "                clf = arr_clf[n]\n",
    "                clf = clf.partial_fit(modified_x,modified_y)\n",
    "                arr_temp_clfs.append(clf)\n",
    "             \n",
    "            rl_pruned_ids = []\n",
    "            #################################### Commented out code that removes the minimum preto based member ###############\n",
    "            arr_clf = arr_temp_clfs\n",
    "            #remove one classifier if the pool has reached..\n",
    "            remove_index = 0\n",
    "            start1 = timer()\n",
    "            if(len(arr_clf) == ensemble_pool_size):\n",
    "                least_weight = arr_weights[0]\n",
    "                for q in range (1,len(arr_weights)):\n",
    "                    w_q = arr_weights[q]\n",
    "                    if(w_q < least_weight):\n",
    "                        remove_index = q\n",
    "                arr_clf = np.delete(arr_clf,remove_index)\n",
    "                arr_weights = np.delete(arr_weights,remove_index)\n",
    "            global elt_global\n",
    "            end1 = timer()\n",
    "            elt= end1-start1\n",
    "            elt_global += elt    \n",
    "            ######################### add new classifier to the pool after training it with the current window.#####################\n",
    "            obj_clf1 = DetectorClassifier(HoeffdingTreeClassifier())\n",
    "            clf_temp =obj_clf1.partial_fit(modified_x,modified_y)\n",
    " \n",
    "            arr_weights = np.append(arr_weights,0)\n",
    "            arr_clf = np.append(arr_clf,clf_temp)\n",
    "            \n",
    "            preq_Qtable = np.delete(preq_Qtable, remove_index, axis=1)\n",
    "            preq_Qtable = np.delete(preq_Qtable, remove_index, axis=0)\n",
    "                        \n",
    "            row_of_ones = np.zeros((1, preq_Qtable.shape[1]), dtype=preq_Qtable.dtype)\n",
    "            preq_Qtable = np.vstack((preq_Qtable, row_of_ones))\n",
    "\n",
    "            # Add a column containing ones for all rows\n",
    "            column_of_ones = np.zeros((preq_Qtable.shape[0], 1), dtype=preq_Qtable.dtype)\n",
    "            preq_Qtable = np.hstack((preq_Qtable, column_of_ones))\n",
    "\n",
    "            if(len(arr_clf) == ensemble_pool_size):\n",
    "\n",
    "                rl_pruned_ids,preq_Qtable = get_pruned_rl_members(arr_clf,x_preq, y_preq,window_counter,preq_Qtable)\n",
    "            ##########################################################################################################        \n",
    "            current_w = 0\n",
    "            prev_win_x = x_preq\n",
    "            prev_win_y =  y_preq\n",
    "            \n",
    "            end = timer()\n",
    "            elapsed_time = end - start\n",
    "            arr_elapsedtime.append(elapsed_time)\n",
    "            print(elapsed_time)\n",
    "            #if(window_counter % 50 == 0):\n",
    "            #    np.savetxt(output_folder + file_out_prefix+ \"-\"  +str(window_counter) +'.csv', np.c_[arr_recall_0,arr_recall_1,arr_gmean], delimiter=',',fmt='%2.5f')\n",
    "               \n",
    "    \n",
    "    np.savetxt(output_folder + file_out_prefix + '.csv',  np.c_[arr_recall_0,arr_recall_1,arr_gmean,arr_elapsedtime], delimiter=',',fmt='%1.2f')\n",
    "    \n",
    "def initialize_q_table(state_space, action_space):\n",
    "  Qtable = np.zeros((state_space, action_space))\n",
    "  return Qtable    \n",
    "    \n",
    "def take_step(ensemble,action,X_test,y_test,prev_perf):\n",
    "    global ensemble_pool_size    \n",
    "    ensemble.append(action)    \n",
    "    eclf = VotingClassifier(estimators = ensemble, voting='soft') \n",
    "    eclf.estimators_ = ensemble\n",
    "    eclf.le_ = LabelEncoder().fit(np.unique([0, 1]))\n",
    "\n",
    "    #print(y_test)\n",
    "    y_pred = np.zeros(y_test.shape)\n",
    "    \n",
    "    if(len(ensemble) == 1):\n",
    "        eclf = ensemble[0]\n",
    "        \n",
    "    y_pred = np.zeros(y_test.shape)\n",
    "    \n",
    "    zero_corrects = 0\n",
    "    zeros_count = 0\n",
    "    one_corrects = 0\n",
    "    ones_count = 0\n",
    "\n",
    "    num_zeros = np.count_nonzero(y_test == 0)\n",
    "    num_ones = np.count_nonzero(y_test == 1)\n",
    "       \n",
    "    if len(X_test.shape) == 1:\n",
    "        X_test = X_test.reshape(1, -1)  # Reshape to a 2D array with a single row\n",
    "\n",
    "    # Predict all examples in X_test\n",
    "    predictions = eclf.predict(X_test)\n",
    "\n",
    "    # Compare predictions with y_test\n",
    "    zero_corrects = np.sum((y_test == 0) & (predictions == 0))\n",
    "    one_corrects = np.sum((y_test == 1) & (predictions == 1))     \n",
    "   \n",
    "    recall_0 = zero_corrects / num_zeros\n",
    "    if(ones_count ==0):\n",
    "        recall_1 = 0\n",
    "    else:\n",
    "        recall_1 = one_corrects / num_ones\n",
    "    weight_en = recall_0*maj_weight + recall_1*min_weight\n",
    "    \n",
    "    reward = weight_en - prev_perf\n",
    "\n",
    "    new_state = action\n",
    "    done = False\n",
    "    if(len(ensemble)>ensemble_pool_size or reward > 0.99):\n",
    "        done = True\n",
    "    return new_state, reward, done, 0,weight_en\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    data = df.values\n",
    "    return data, data[:, :-1], data[:, -1]\n",
    "\n",
    "def delete_files_from_folder(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def train_rl(gamma,learning_rate,min_epsilon, max_epsilon, decay_rate, max_steps, Qtable,X_test,y_test,classifiers,window_counter):\n",
    "  global rl_episodes \n",
    "  global restart_threshold\n",
    "  global rl_each_step_episodes\n",
    "  global ensemble_pool_size\n",
    "  ep = 0 \n",
    "  rl_episodes_to_use = rl_episodes\n",
    "  if(window_counter==2):\n",
    "     rl_episodes_to_use = rl_episodes\n",
    "\n",
    "  elif( window_counter % restart_threshold ==0):\n",
    "    rl_episodes_to_use = rl_episodes\n",
    "  else:\n",
    "    rl_episodes_to_use = rl_each_step_episodes\n",
    "  for episode in range(0,rl_episodes_to_use):\n",
    "    ep += 1\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "\n",
    "    running_ep_val = epsilon\n",
    "    # Reset the environment\n",
    "    state_index= random.randint(0, ensemble_pool_size-1)\n",
    "\n",
    "    state = classifiers[state_index]\n",
    "    step = 0\n",
    "    done = False\n",
    "    ensemble = []\n",
    "    \n",
    "    predictive_performance = 0.90\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "      action_index = epsilon_greedy_policy(Qtable, state_index, epsilon,False)\n",
    "      if(action_index==state_index or (action_index in ensemble)):\n",
    "        continue\n",
    "      ensemble.append(state)\n",
    "\n",
    "      action = classifiers[action_index]\n",
    "\n",
    "      new_state, reward, done, info,predictive_performance = take_step(ensemble,action,X_test,y_test,predictive_performance)\n",
    "      new_state = action_index\n",
    "\n",
    "      Qtable[state_index][action_index] = Qtable[state_index][action_index] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state_index][action_index])\n",
    "      # If done, finish the episode\n",
    "      if done:\n",
    "        break\n",
    "     \n",
    "      # Our state is the new state\n",
    "      state_index =new_state\n",
    "      state =  classifiers[new_state]\n",
    "  return Qtable\n",
    "\n",
    "def epsilon_greedy_policy(Qtable, state, epsilon,running_ep_val):\n",
    "\n",
    "    random_int = random.uniform(0,1)\n",
    "    if running_ep_val:\n",
    "        action = np.argmax(Qtable[state])\n",
    "    elif random_int > epsilon:\n",
    "        action = np.argmax(Qtable[state])\n",
    "    else:\n",
    "        action = random.randint(0, ensemble_pool_size-1)\n",
    "\n",
    "    return action\n",
    "\n",
    "def get_pruned_rl_members(trained_members,X_test,y_test,window_counter,QTable):\n",
    "\n",
    "    global restart_threshold\n",
    "    if(window_counter==2):\n",
    "        Qtable_ens = initialize_q_table(ensemble_pool_size,ensemble_pool_size)\n",
    "\n",
    "    elif(window_counter % restart_threshold ==0):\n",
    "        Qtable_ens = initialize_q_table(ensemble_pool_size,ensemble_pool_size)\n",
    "    else:\n",
    "        Qtable_ens = QTable\n",
    "    \n",
    "    global learning_rate\n",
    "    global decay_factor\n",
    "\n",
    "    # Environment parameters\n",
    "    max_steps = 15             \n",
    "    gamma = 0.95               \n",
    "    eval_seed = []             \n",
    "\n",
    "    # Exploration parameters\n",
    "    max_epsilon = 1.0           \n",
    "    min_epsilon = 0.05           \n",
    " \n",
    "    \n",
    "    ensemble_arr = []\n",
    "    weights_arr = []\n",
    "    Qtable = train_rl(gamma,learning_rate,min_epsilon, max_epsilon, decay_factor, max_steps, Qtable_ens,X_test,y_test,trained_members,window_counter)\n",
    "    classifiers = trained_members\n",
    "    rl_pruned_ids = []\n",
    "    ensemble = []\n",
    "    state_index= random.randint(0, ensemble_pool_size-1)\n",
    "    rl_pruned_ids.append(state_index)\n",
    "    state = classifiers[state_index]\n",
    "    ensemble.append(state)\n",
    "    step = 0\n",
    "    done = False\n",
    "    ensemble = []\n",
    "\n",
    "    \n",
    "    #max_perf\n",
    "    max_gmean = 0\n",
    "    max_index = 0\n",
    "    step_index= -1\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "        step_index += 1\n",
    "        action_index = epsilon_greedy_policy(Qtable, state_index,0, True)\n",
    "\n",
    "        if(action_index==state_index or (action_index in rl_pruned_ids)):\n",
    "            continue\n",
    "        \n",
    "        rl_pruned_ids.append(action_index)\n",
    "\n",
    "        action = classifiers[action_index]\n",
    "\n",
    "        ensemble.append(action)\n",
    "\n",
    "        eclf = VotingClassifier(estimators = ensemble, voting='soft') \n",
    "        eclf.estimators_ = ensemble\n",
    "        eclf.le_ = LabelEncoder().fit(np.unique([0, 1]))\n",
    "\n",
    "        num_zeros = np.count_nonzero(y_test == 0)\n",
    "        num_ones = np.count_nonzero(y_test == 1)\n",
    "            \n",
    "        if len(X_test.shape) == 1:\n",
    "            X_test = X_test.reshape(1, -1)  # Reshape to a 2D array with a single row\n",
    "\n",
    "        # Predict all examples in X_test\n",
    "        predictions = eclf.predict(X_test)\n",
    "\n",
    "        # Compare predictions with y_test\n",
    "        zero_corrects = np.sum((y_test == 0) & (predictions == 0))\n",
    "        one_corrects = np.sum((y_test == 1) & (predictions == 1))     \n",
    "\n",
    "        recall_0 = zero_corrects / num_zeros\n",
    "        if(num_ones ==0):\n",
    "            recall_1 = 0\n",
    "        else:\n",
    "            recall_1 = one_corrects / num_ones\n",
    "        gmean = math.sqrt (recall_0 * recall_1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(gmean > max_gmean):\n",
    "            max_index = step_index\n",
    "            max_gmean = gmean\n",
    "        \n",
    "        state_index =action_index\n",
    "        state =  classifiers[state_index]\n",
    "        done = False\n",
    "        if(len(ensemble) == pruned_ensemble_size ):\n",
    "\n",
    "            break\n",
    "\n",
    "    return rl_pruned_ids, Qtable              \n",
    "            \n",
    "#*********************************  Main ******************************** #\n",
    "\n",
    "global imbalance_threshold\n",
    "global arr_recall_0\n",
    "global arr_recall_1\n",
    "global arr_gmean\n",
    "global restart\n",
    "global restart_threshold\n",
    "global f1_overlap_value\n",
    "global maj_weight\n",
    "global min_weight\n",
    "global ens_weight\n",
    "global arr_ord_cols\n",
    "global preq_Qtable\n",
    "global restart_threshold\n",
    "global min_life_max\n",
    "global min_life_decay_factor\n",
    "global output_folder\n",
    "global stream_folder\n",
    "\n",
    "global ensemble_pool_size\n",
    "global pruned_ensemble_size\n",
    "global rl_pruned_ids\n",
    "global learning_rate\n",
    "global decay_factor\n",
    "global minority_buffer_x\n",
    "global minority_buffer_y\n",
    "minority_buffer_x = []\n",
    "minority_buffer_y = []\n",
    "global df_buffer_x\n",
    "global rl_each_step_episodes\n",
    "global arr_elapsedtime\n",
    "global elt_global\n",
    "global disable_buffer\n",
    "\n",
    "\n",
    "elt_global = 0\n",
    "df_buffer_x = pd.DataFrame()\n",
    "f1_overlap_value = 0\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd = \"C:/Users/Lenovo/EMRIL\"  \n",
    "#cwd = \"D:\\\\usman-data\"\n",
    "output_folder = cwd +  '/output/'\n",
    "\n",
    "#  make sure it exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "stream_folder = cwd +  '/data_set/'\n",
    "\n",
    "arr_elapsedtime = []\n",
    "arr_gmean = []\n",
    "arr_recall_0 = []\n",
    "arr_recall_1 = []\n",
    "rl_pruned_ids = []\n",
    "\n",
    "ensemble_pool_size = 15 #ensemble pool size\n",
    "pruned_ensemble_size =8#pruned ensemble size\n",
    "restart_threshold = 50 #batches after q-table is emptied\n",
    "rl_episodes = 5 #on restart\n",
    "rl_each_step_episodes =1\n",
    "\n",
    "n_train = 200 #no of instances to train the model (offline)\n",
    "w =200 #batch size\n",
    "overlap_threshold_f1 = 0.0 #overlap threshold\n",
    "imbalance_ratio_threshold =1.01 #IR threshold\n",
    "disjuncts_threshold =2 #MinD Threshold\n",
    "disjunct_threshold_perc_maj = 1.0 #overlap removal threshold\n",
    "maj_weight = 0.1 #lambda_0 majority weight in ensemble\n",
    "min_weight = 0.9 #Lambda_1 minority weight in ensemble\n",
    "min_life_max = 0.99 #minoirty instance life max value\n",
    "min_life_decay_factor = 0.03 #minority instance life decay factor\n",
    "disable_buffer = False\n",
    "\n",
    "#/*If data stream contains ordinal cols, provide indices here*/\n",
    "arr_ord_cols= []\n",
    "#arr_ord_cols = [6,7,8,9,10] #1-based index  GMSC\n",
    "#arr_ord_cols = [13,14,15,16,17,18,19,20,21] #1-based index  IJCNN1\n",
    "#arr_ord_cols = [10,11,12] #1-based index  LOAN\n",
    "#arr_ord_cols = [1,2] #1-based index  Mixed\n",
    "\n",
    "#filename = \"v5_imb.csv\"\n",
    "#filename = \"v9_imb.csv\"\n",
    "#filename = \"ijcnn1-full-30oct2022.csv\"\n",
    "#filename = \"cod-rna-311022.csv\"\n",
    "#filename = \"MiniBooNE_PID_Mod.csv\"\n",
    "#filename =  \"GMSC.csv\"\n",
    "#filename = \"loan_191122.csv\"\n",
    "filename = \"noaa.csv\"\n",
    "#filename = \"mixed50K_Static01Abr.csv\"\n",
    "\n",
    "\n",
    "f_arr = filename.split(\".\")\n",
    "\n",
    "filename = stream_folder  + filename\n",
    "\n",
    "Xy, X, y = read_data(filename)\n",
    "\n",
    "\n",
    "# Set x,y as numeric\n",
    "X = X.astype(float)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "ups =  np.count_nonzero(y == 1)\n",
    "downs = np.count_nonzero(y == 0)\n",
    "print(\"1s:\",str(ups/n_samples))\n",
    "print(\"0s:\",str(downs/n_samples))\n",
    "\n",
    "#create the minority buffer structure\n",
    "cols_str = []\n",
    "for f in range(1,n_features+1):\n",
    "    cols_str.append(str(f))\n",
    "cols_str.append(\"life\")\n",
    "cols_str.append(\"recall_weight\")\n",
    "cols_str.append(\"total_weight\")\n",
    "df_buffer_x = pd.DataFrame(columns = cols_str)\n",
    "for k in range (1,11):\n",
    "    elt_global = 0\n",
    "    decay_factor = 0.005\n",
    "    learning_rate = 0.8    \n",
    "    arr_recall_0= []\n",
    "    arr_recall_1= []\n",
    "    arr_gmean= []\n",
    "    arr_elapsedtime = []\n",
    "    df_buffer_x = pd.DataFrame(columns = cols_str)\n",
    "    \n",
    "    file_out_prefix = \"EMRILs_\" + f_arr[0] + \"_\" + str(k) \n",
    "    clf = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "    # Example of usage with stream-based data\n",
    "    clfs = [clf]\n",
    "    clfs_label = [\"Hoeffding Tree Classifier\"]\n",
    "    for i in range(len(clfs)):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            prequential(w,Xy,X, y, clfs[i], n_features,overlap_threshold_f1,\n",
    "                        imbalance_ratio_threshold,disjunct_threshold_perc_maj,file_out_prefix,n_train)\n",
    "sys.exit()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bd2d9-e537-4f91-9b72-6af2994c9b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
